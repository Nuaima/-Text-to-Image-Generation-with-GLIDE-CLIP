# ğŸ–¼ï¸ Text-to-Image Generation with GLIDE + CLIP

This repository contains an implementation of **GLIDE** (Guided Language to Image Diffusion for Generation and Editing) with **CLIP-based guidance** for text-to-image generation.  
It takes a **text prompt** and produces **high-resolution (256Ã—256) images** by first generating a low-resolution sample and then upscaling it with an upsampler model.

---

## ğŸš€ Features
- Generate images from any text description.
- Uses **CLIP guidance** to align images with the text prompt.
- Supports **GPU acceleration (CUDA)** for faster sampling.
- Produces **64Ã—64 â†’ 256Ã—256 upsampled images**.
- Easy to modify for different prompts, batch sizes, and sampling steps.

---

## ğŸ“‚ Repository Structure
ğŸ“¦ glide-text2im-project/
â”œâ”€â”€ ğŸ“„ clip_guided_notebook.ipynb # Main Colab notebook implementation
â”œâ”€â”€ ğŸ“„ README.md # Project documentation
â””â”€â”€ ğŸ“ samples/ # Generated images 

---

ğŸ“¦ Dependencies

The following Python libraries are required:

torch
torchvision
pillow
numpy
tqdm
ipython
